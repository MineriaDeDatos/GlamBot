import requests
import pyttsx3
import speech_recognition as sr
import json

# Direcci√≥n del servidor local (aseg√∫rate de que LM Studio est√© corriendo con el modelo)
SERVER_URL = "http://192.168.1.88:1234/v1/chat/completions"
USER_DATA_URL = "http://192.168.1.88:5000/get_combined_data"  # URL para obtener los datos combinados

# Definir variables para el modelo
NOMBRE_MODELO = "Meta-Llama-3.1-8B-Instruct"  # Nombre del modelo en LM Studio

# Inicializaci√≥n de la voz
engine = pyttsx3.init()

# Configuraci√≥n de voz personalizada
VOZ_OBJETIVO = "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_ES-MX_SABINA_11.0"

# Buscar la voz exacta
voz_encontrada = None
for voz in engine.getProperty('voices'):
    if voz.id == VOZ_OBJETIVO:
        voz_encontrada = voz
        break

if voz_encontrada:
    engine.setProperty('voice', voz_encontrada.id)
    print(f"‚úÖ Voz seleccionada: {voz_encontrada.name}")
else:
    print("‚ö†Ô∏è Voz preferida no encontrada. Usando voz por defecto.")
    print(f"Voces disponibles: {[voz.name for voz in engine.getProperty('voices')]}")

# Configuraci√≥n de la velocidad de habla y volumen
engine.setProperty("rate", 160)  # Velocidad de habla
engine.setProperty("volume", 0.9)  # Volumen


# Funci√≥n para limpiar el texto (eliminar caracteres innecesarios como # y *)
def clean_text(text):
    return text.replace("#", "").replace("*", "").replace("**", "").strip()


# Funci√≥n para convertir el texto en voz
def speak(text):
    text = clean_text(text)  # Limpiar el texto antes de hablar
    engine.say(text)
    engine.runAndWait()


# Funci√≥n para capturar la entrada de voz del usuario
def listen():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        try:
            recognizer.adjust_for_ambient_noise(source, duration=0.8)
            print("\nüé§ [Escuchando...]")
            audio = recognizer.listen(source, timeout=12, phrase_time_limit=18)
            text = recognizer.recognize_google(audio, language="es-ES")
            print(f"üë§ [Usuario]: {text}")
            return text
        except sr.WaitTimeoutError:
            print("‚è≥ [Sistema]: Tiempo de espera agotado")
            return None
        except Exception as e:
            print(f"‚ùå [Error]: {str(e)}")
            return None


# Funci√≥n para generar respuesta con el modelo local (LM Studio)
def generate_response_with_local_model(user_input, features, skin_type, name, conversation_history):
    try:
        # Convertir las caracter√≠sticas a una descripci√≥n en texto
        descripcion_features = (
            f"Tengo un rostro {features['rostro']}, ojos {features['ojos']} y piel {features['tono_piel']}. "
            f"Mi tipo de piel es {skin_type}."
        )

        # Mantener el historial de conversaci√≥n
        conversation_history.append({"role": "user", "content": user_input})

        # Datos de entrada para el modelo, incluyendo el historial de la conversaci√≥n
        payload = {
            "model": NOMBRE_MODELO,
            "messages": [{"role": "system", "content": f"Eres un experto en maquillaje y belleza personal. "
                                                       f"Siempre me llamas '{name}'. Mi informaci√≥n de belleza es la siguiente: {descripcion_features}"},
                         *conversation_history],
            "temperature": 0.7,  # Nivel de creatividad del modelo
            "max_tokens": 300  # L√≠mite de tokens generados
        }

        # Realizar la petici√≥n POST al servidor
        response = requests.post(SERVER_URL, json=payload)

        # Si la respuesta es exitosa, procesarla
        if response.status_code == 200:
            response_data = response.json()
            answer = response_data.get('choices', [{}])[0].get('message', {}).get('content', '')

            # Si la respuesta no es sobre maquillaje, redirigir al tema correcto
            if "no relacionado" in answer.lower() or "pregunta fuera de tema" in answer.lower():
                return f"{name}, recuerda que solo hablo sobre maquillaje y belleza. ¬øQuieres consejos de maquillaje?"

            return answer
        else:
            print(f"‚ö†Ô∏è Error al obtener la respuesta del modelo: {response.status_code}")
            return "Ocurri√≥ un error al procesar tu solicitud."

    except Exception as e:
        print(f"‚ö†Ô∏è Error al realizar la solicitud: {e}")
        return "Ocurri√≥ un error procesando tu solicitud."


# Funci√≥n para obtener los datos del usuario desde el servidor
def get_user_features():
    try:
        response = requests.get(USER_DATA_URL)
        if response.status_code == 200:
            return response.json()
        else:
            print(f"‚ö†Ô∏è Error al obtener los datos del usuario: {response.status_code}")
            return None
    except Exception as e:
        print(f"‚ö†Ô∏è Error al hacer la solicitud GET: {e}")
        return None


# Funci√≥n para preguntar preferencias al usuario
def preguntar_preferencias(name):
    speak(f"{name}, ¬øqu√© tipo de maquillaje prefieres hoy?")
    print(f"ü§ñ [GlamBot]: {name}, ¬øqu√© tipo de maquillaje prefieres hoy?")
    preferencia = listen()

    if not preferencia:
        return "natural"  # Valor por defecto si no responde

    return preferencia


# Funci√≥n para generar el prompt final de maquillaje basado en toda la conversaci√≥n
def generate_makeup_prompt(conversation_history):
    prompt = "Generar maquillaje basado en la siguiente conversaci√≥n:\n"

    for message in conversation_history:
        if message["role"] == "user":
            prompt += f"Usuario: {message['content']}\n"
        elif message["role"] == "assistant":
            prompt += f"Asistente: {message['content']}\n"

    return prompt


# Funci√≥n principal para interactuar con el asistente
def interact_with_assistant():
    # Obtener los datos de morfolog√≠a del usuario
    user_features = get_user_features()

    if not user_features:
        speak("Lo siento, no pude obtener los datos de morfolog√≠a. ¬øPuedes intentar de nuevo?")
        print("‚ö†Ô∏è [Sistema]: No se pudieron obtener los datos del usuario.")
        return

    # Extraer el nombre y las caracter√≠sticas del usuario
    name = user_features.get("name", "Usuario")
    features = user_features.get("features", {})
    skin_type = user_features.get("skin_type", "Desconocido")

    print(f"ü§ñ [GlamBot]: Hola {name}, soy GlamBot. ¬øEn qu√© puedo ayudarte hoy?")
    speak(f"Hola {name}, soy GlamBot. ¬øEn qu√© puedo ayudarte hoy?")

    # Crear historial de conversaci√≥n vac√≠o
    conversation_history = []

    while True:
        user_input = listen()

        if not user_input:
            continue

        # Verificar si el usuario quiere salir
        if any(word in user_input.lower() for word in ["salir", "terminar", "adi√≥s"]):
            farewell = f"¬°Gracias por conversar, {name}! Hasta la pr√≥xima."
            print(f"ü§ñ [GlamBot]: {farewell}")
            speak(farewell)

            # Generar el prompt final basado en la conversaci√≥n
            final_prompt = generate_makeup_prompt(conversation_history)
            print(f"üåü [Generado]: {final_prompt}")

            # Aqu√≠ puedes almacenar el prompt o hacer lo que desees con √©l
            # Por ejemplo, guardarlo en un archivo
            with open("final_prompt.txt", "w") as f:
                f.write(final_prompt)

            break

        # Preguntar preferencias usando el nombre del usuario
        preferencia_maquillaje = preguntar_preferencias(name)

        # Generar respuesta con el modelo incluyendo las preferencias y datos de caracter√≠sticas
        input_con_preferencia = f"{user_input}. Me gustar√≠a un maquillaje {preferencia_maquillaje}."
        response = generate_response_with_local_model(input_con_preferencia, features, skin_type, name,
                                                      conversation_history)

        print(f"ü§ñ [GlamBot]: {response}")
        speak(response)

        # Agregar la respuesta del asistente al historial
        conversation_history.append({"role": "assistant", "content": response})


# Ejecutar el asistente
if __name__ == "__main__":
    interact_with_assistant()



-------------------------------------------------------------------------------------------------

import requests
import pyttsx3
import speech_recognition as sr
import json
import base64
from flask import Flask, request, jsonify
from io import BytesIO

# Configuraci√≥n del servidor y el modelo
SERVER_URL = "http://192.168.1.88:1234/v1/chat/completions"
USER_DATA_URL = "http://192.168.1.88:5000/get_combined_data"  # URL para obtener los datos combinados
NOMBRE_MODELO = "Meta-Llama-3.1-8B-Instruct"  # Nombre del modelo en LM Studio

# Inicializaci√≥n de la voz
engine = pyttsx3.init()
engine.setProperty("rate", 160)  # Velocidad de habla
engine.setProperty("volume", 0.9)  # Volumen
VOZ_OBJETIVO = "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_ES-MX_SABINA_11.0"

# Configuraci√≥n de la voz
voz_encontrada = None
for voz in engine.getProperty('voices'):
    if voz.id == VOZ_OBJETIVO:
        voz_encontrada = voz
        break
if voz_encontrada:
    engine.setProperty('voice', voz_encontrada.id)

# Flask para manejar interacciones
app = Flask(__name__)


# Funci√≥n para obtener los datos del usuario desde el servidor
def get_user_features():
    try:
        response = requests.get(USER_DATA_URL)
        if response.status_code == 200:
            return response.json()
        else:
            print(f"‚ö†Ô∏è Error al obtener los datos del usuario: {response.status_code}")
            return None
    except Exception as e:
        print(f"‚ö†Ô∏è Error al hacer la solicitud GET: {e}")
        return None


# Funci√≥n para limpiar el texto (eliminar caracteres innecesarios)
def clean_text(text):
    return text.replace("#", "").replace("*", "").replace("**", "").strip()

def generate_response_with_local_model(user_input, features, skin_type, name, conversation_history):
    try:
        user_input = clean_text(user_input)

        # Descripci√≥n de las caracter√≠sticas
        descripcion_features = (
            f"Tengo un rostro {features['rostro']}, ojos {features['ojos']} y piel {features['tono_piel']}. "
            f"Mi tipo de piel es {skin_type}."
        )

        conversation_history.append({"role": "user", "content": user_input})

        payload = {
            "model": NOMBRE_MODELO,
            "messages": [{"role": "system",
                          "content": f"Eres un experto en maquillaje y belleza personal. Siempre me llamas 'GlamBot'. Mi informaci√≥n de belleza es la siguiente: {descripcion_features}"},
                         *conversation_history],
            "temperature": 0.7,
            "max_tokens": 300
        }

        # Llamada al modelo
        response = requests.post(SERVER_URL, json=payload)
        if response.status_code == 200:
            response_data = response.json()
            generated_content = response_data.get('choices', [{}])[0].get('message', {}).get('content', '')

            # Regresar tanto la respuesta como el prompt generado
            return generated_content, payload["messages"]
        else:
            return "Error al procesar la solicitud", None
    except Exception as e:
        return f"Error: {e}", None

# Funci√≥n para convertir texto en voz y devolverlo como base64
def generate_audio_response(text):
    engine.save_to_file(text, "response.mp3")
    engine.runAndWait()

    # Convertir audio a base64
    with open("response.mp3", "rb") as audio_file:
        audio_base64 = base64.b64encode(audio_file.read()).decode('utf-8')

    return audio_base64


# Funci√≥n para capturar la entrada de voz del usuario (escucha)
def listen():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        try:
            recognizer.adjust_for_ambient_noise(source, duration=0.8)
            print("\nüé§ [Escuchando...]")
            audio = recognizer.listen(source, timeout=12, phrase_time_limit=18)
            text = recognizer.recognize_google(audio, language="es-ES")
            print(f"üë§ [Usuario]: {text}")
            return clean_text(text)  # Limpiar el texto antes de devolverlo
        except sr.WaitTimeoutError:
            print("‚è≥ [Sistema]: Tiempo de espera agotado")
            return None
        except Exception as e:
            print(f"‚ùå [Error]: {str(e)}")
            return None


# Funci√≥n principal para interactuar con el asistente
def interact_with_assistant(user_input, features, skin_type, name, conversation_history):
    if not user_input:
        return "Error: No input received"

    # Aqu√≠ cambiamos la presentaci√≥n para que siempre se identifique como "GlamBot"
    response = generate_response_with_local_model(user_input, features, skin_type, "GlamBot", conversation_history)

    # Agregar la respuesta del asistente al historial de conversaci√≥n
    conversation_history.append({"role": "assistant", "content": response})

    return response


# Ruta para recibir mensajes del cliente y generar la respuesta
@app.route("/interact", methods=["POST"])
def interact():
    # Obtener los datos del usuario
    user_features = get_user_features()
    if user_features is None:
        return jsonify({"error": "No se pudieron obtener los datos del usuario"}), 500

    data = request.json
    user_input = data.get('message')
    features = user_features.get("features", {})
    skin_type = user_features.get("skin_type", "desconocido")
    name = user_features.get("name", "Usuario")
    conversation_history = data.get('conversation_history', [])

    # Limpiar el texto del usuario antes de procesarlo
    user_input = clean_text(user_input)

    # Obtener la respuesta del modelo
    response_text = interact_with_assistant(user_input, features, skin_type, name, conversation_history)

    # Generar audio para la respuesta
    audio_base64 = generate_audio_response(response_text)

    return jsonify({
        "text_response": response_text,
        "audio_response": audio_base64
    })


# Ejecutar el servidor Flask
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001)


-------Ultima versi√≥n

import requests
import pyttsx3
import base64
from flask import Flask, request, jsonify

# Configuraci√≥n
SERVER_URL = "http://192.168.1.88:1234/v1/chat/completions"
USER_DATA_URL = "http://192.168.1.88:5000/get_combined_data"
NOMBRE_MODELO = "Meta-Llama-3.1-8B-Instruct"

# Palabras clave permitidas
ALLOWED_KEYWORDS = [
    'maquillaje', 'belleza', 'piel', 'ojos', 'labios', 'sombras', 'base',
    'corrector', 'rubor', 'brillo', 'tono', 'cutis', 'crema', 'contorno',
    'iluminador', 'polvo', 'rimel', 'delineador', 'pesta√±as', 'cejas'
]

# Palabras clave de cierre
CLOSING_PHRASES = ['adios', 'hasta luego', 'terminar', 'finalizar', 'cerrar']

# Inicializaci√≥n de voz
engine = pyttsx3.init()
engine.setProperty("rate", 160)
engine.setProperty("volume", 0.9)
VOZ_OBJETIVO = "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_ES-MX_SABINA_11.0"

# Configuraci√≥n de voz
for voz in engine.getProperty('voices'):
    if voz.id == VOZ_OBJETIVO:
        engine.setProperty('voice', voz.id)
        break

app = Flask(__name__)

def get_user_features():
    try:
        response = requests.get(USER_DATA_URL)
        return response.json() if response.status_code == 200 else {}
    except:
        return {}

def clean_text(text):
    return text.replace("#", "").replace("*", "").replace("**", "").strip()

def is_valid_topic(user_input):
    return any(keyword in user_input.lower() for keyword in ALLOWED_KEYWORDS)

def generate_conversation_prompt(features, skin_type, name):
    return (
        f"Eres GlamBot, experto en belleza. Pres√©ntate formalmente al inicio. "
        f"Responde SOLO sobre maquillaje/belleza. Datos del usuario: "
        f"tono piel {features.get('tono_piel', 'neutral')}, "
        f"ojos {features.get('ojos', 'marrones')}, "
        f"rostro {features.get('rostro', 'ovalado')}, "
        f"piel {skin_type}. Dir√≠gete SIEMPRE a '{name}'."
    )

def generate_final_prompt(features, skin_type, conversation_history):
    preferencias = {
        'colores': set(),
        'productos': set(),
        'estilos': set()
    }

    for msg in conversation_history:
        content = msg['content'].lower()
        if 'color' in content:
            preferencias['colores'].add(content.split('color')[-1].split()[0])
        if 'producto' in content:
            preferencias['productos'].add(content.split('producto')[-1].split()[0])
        if 'estilo' in content:
            preferencias['estilos'].add(content.split('estilo')[-1].split()[0])

    return (
        f"MAQUILLAJE PERSONALIZADO\n"
        f"CARACTER√çSTICAS:\n"
        f"- Tono piel: {features.get('tono_piel', 'neutral')}\n"
        f"- Ojos: {features.get('ojos', 'marrones')}\n"
        f"- Rostro: {features.get('rostro', 'ovalado')}\n"
        f"- Tipo piel: {skin_type}\n\n"
        f"PREFERENCIAS DETECTADAS:\n"
        f"Colores: {', '.join(preferencias['colores'] or ['N/A'])}\n"
        f"Productos: {', '.join(preferencias['productos'] or ['N/A'])}\n"
        f"Estilos: {', '.join(preferencias['estilos'] or ['N/A'])}\n\n"
        f"REQUISITOS:\n"
        f"1. Paleta {('c√°lida' if 'c√°lido' in features.get('tono_piel', '') else 'fr√≠a')}\n"
        f"2. T√©cnicas para rostro {features.get('rostro', 'ovalado')}\n"
        f"3. Durabilidad para piel {skin_type}\n"
        f"4. Incluir recomendaciones de aplicaci√≥n\n"
        f"FORMATO: Tutorial paso a paso con especificaciones t√©cnicas"
    )

@app.route("/interact", methods=["POST"])
def interact():
    user_features = get_user_features()
    data = request.json
    user_input = clean_text(data.get('message', '')).lower()
    conversation_history = data.get('conversation_history', [])
    name = user_features.get("name", "Usuario")
    features = user_features.get("features", {})
    skin_type = user_features.get("skin_type", "normal")

    # Asegurar presentaci√≥n en primer mensaje
    if not conversation_history:
        presentation = f"Hola {name}, soy GlamBot ‚ú® Tu asistente de belleza personal. ¬øQu√© look deseas crear hoy?"
        conversation_history.insert(0, {"role": "assistant", "content": presentation})

        return jsonify({
            "text_response": presentation,
            "audio_response": generate_audio_response(presentation),
            "conversation_history": conversation_history
        })

    # Detectar cierre de conversaci√≥n
    if any(phrase in user_input for phrase in CLOSING_PHRASES):
        final_prompt = generate_final_prompt(features, skin_type, conversation_history)
        despedida = f"¬°Hasta pronto {name}! üíÑ Aqu√≠ tienes tu recomendaci√≥n personalizada:"

        return jsonify({
            "text_response": despedida,
            "prompt_response": final_prompt,
            "audio_response": generate_audio_response(despedida)
        })

    # Validar tema
    if not is_valid_topic(user_input):
        default_response = "Solo puedo ayudarte con temas de belleza y maquillaje."
        return jsonify({
            "text_response": default_response,
            "audio_response": generate_audio_response(default_response)
        })

    # Generar respuesta normal
    system_prompt = generate_conversation_prompt(features, skin_type, name)
    payload = {
        "model": NOMBRE_MODELO,
        "messages": [
            {"role": "system", "content": system_prompt},
            *conversation_history,
            {"role": "user", "content": user_input}
        ],
        "temperature": 0.7,
        "max_tokens": 300
    }

    try:
        response = requests.post(SERVER_URL, json=payload)
        if response.status_code != 200:
            raise Exception("Error en el procesamiento del modelo")

        response_text = response.json()['choices'][0]['message']['content']
        conversation_history.append({"role": "user", "content": user_input})
        conversation_history.append({"role": "assistant", "content": response_text})

        return jsonify({
            "text_response": response_text,
            "audio_response": generate_audio_response(response_text),
            "conversation_history": conversation_history
        })

    except Exception as e:
        error_msg = f"Error: {str(e)}"
        return jsonify({
            "text_response": error_msg,
            "audio_response": generate_audio_response(error_msg)
        })

def generate_audio_response(text):
    engine.save_to_file(text, "response.mp3")
    engine.runAndWait()
    with open("response.mp3", "rb") as f:
        return base64.b64encode(f.read()).decode('utf-8')

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001)


----------- Previo

import requests
import pyttsx3
import base64
from flask import Flask, request, jsonify

# Configuraci√≥n del servidor y el modelo
SERVER_URL = "http://192.168.1.88:1234/v1/chat/completions"
USER_DATA_URL = "http://192.168.1.88:5000/get_combined_data"  # URL para obtener los datos combinados
NOMBRE_MODELO = "Meta-Llama-3.1-8B-Instruct"  # Nombre del modelo en LM Studio

# Inicializaci√≥n de la voz
engine = pyttsx3.init()
engine.setProperty("rate", 160)  # Velocidad de habla
engine.setProperty("volume", 0.9)  # Volumen
VOZ_OBJETIVO = "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_ES-MX_SABINA_11.0"

# Configuraci√≥n de la voz
voz_encontrada = None
for voz in engine.getProperty('voices'):
    if voz.id == VOZ_OBJETIVO:
        voz_encontrada = voz
        break
if voz_encontrada:
    engine.setProperty('voice', voz_encontrada.id)

# Flask para manejar interacciones
app = Flask(__name__)


# Funci√≥n para obtener los datos del usuario desde el servidor
def get_user_features():
    try:
        response = requests.get(USER_DATA_URL)
        if response.status_code == 200:
            return response.json()
        else:
            print(f"‚ö†Ô∏è Error al obtener los datos del usuario: {response.status_code}")
            return None
    except Exception as e:
        print(f"‚ö†Ô∏è Error al hacer la solicitud GET: {e}")
        return None


# Funci√≥n para limpiar el texto (eliminar caracteres innecesarios)
def clean_text(text):
    return text.replace("#", "").replace("*", "").replace("**", "").strip()


# Funci√≥n para generar la respuesta con el modelo local (LM Studio)
def generate_response_with_local_model(user_input, features, skin_type, name, conversation_history):
    try:
        # Limpiar el texto del usuario antes de procesarlo
        user_input = clean_text(user_input)

        # Convertir las caracter√≠sticas del usuario a una descripci√≥n
        descripcion_features = (
            f"Tengo un rostro {features['rostro']}, ojos {features['ojos']} y piel {features['tono_piel']}. "
            f"Mi tipo de piel es {skin_type}."
        )

        conversation_history.append({"role": "user", "content": user_input})

        # Datos de entrada para el modelo, incluyendo el historial de conversaci√≥n
        payload = {
            "model": NOMBRE_MODELO,
            "messages": [{"role": "system",
                          "content": f"Eres un experto en maquillaje y belleza personal. Te llamaras a ti mismo GlamBot. Siempre me llamaras '{name}'. Mi informaci√≥n de belleza es la siguiente: {descripcion_features}"},
                         *conversation_history],
            "temperature": 0.7,
            "max_tokens": 300
        }

        # Realizar la petici√≥n POST al servidor
        response = requests.post(SERVER_URL, json=payload)
        if response.status_code == 200:
            response_data = response.json()
            return response_data.get('choices', [{}])[0].get('message', {}).get('content', '')
        else:
            return "Error al procesar la solicitud"
    except Exception as e:
        return f"Error: {e}"


# Funci√≥n para convertir texto en voz y devolverlo como base64
def generate_audio_response(text):
    engine.save_to_file(text, "response.mp3")
    engine.runAndWait()

    # Convertir audio a base64
    with open("response.mp3", "rb") as audio_file:
        audio_base64 = base64.b64encode(audio_file.read()).decode('utf-8')

    return audio_base64


# Ruta para recibir mensajes del cliente y generar la respuesta
@app.route("/interact", methods=["POST"])
def interact():
    # Obtener los datos del usuario
    user_features = get_user_features()
    if user_features is None:
        return jsonify({"error": "No se pudieron obtener los datos del usuario"}), 500

    data = request.json
    user_input = data.get('message')
    features = user_features.get("features", {})
    skin_type = user_features.get("skin_type", "desconocido")
    name = user_features.get("name", "Usuario")
    conversation_history = data.get('conversation_history', [])

    # Limpiar el texto del usuario antes de procesarlo
    user_input = clean_text(user_input)

    # Obtener la respuesta del modelo
    response_text = clean_text(generate_response_with_local_model(user_input, features, skin_type, name, conversation_history))

    # Generar audio para la respuesta
    audio_base64 = generate_audio_response(response_text)

    return jsonify({
        "text_response": response_text,
        "audio_response": audio_base64
    })


# Ejecutar el servidor Flask
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001)
