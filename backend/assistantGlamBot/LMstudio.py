import requests
import pyttsx3
import speech_recognition as sr
import json

# Direcci√≥n del servidor local (aseg√∫rate de que LM Studio est√© corriendo con el modelo)
SERVER_URL = "http://192.168.1.88:1234/v1/chat/completions"

# Definir variables para el usuario y el modelo
NOMBRE_USUARIO = "Karen"  # Nombre del usuario
NOMBRE_MODELO = "Meta-Llama-3.1-8B-Instruct"  # Nombre del modelo en LM Studio

# JSON con datos de morfolog√≠a facial (ejemplo)
MORFOLOGIA_USUARIO = {
    "tipo_rostro": "redondo",
    "ojos": "grandes",
    "color_piel": "clara"
}

# Inicializaci√≥n de la voz
engine = pyttsx3.init()

# Configuraci√≥n de voz personalizada
VOZ_OBJETIVO = "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_ES-MX_SABINA_11.0"

# Buscar la voz exacta
voz_encontrada = None
for voz in engine.getProperty('voices'):
    if voz.id == VOZ_OBJETIVO:
        voz_encontrada = voz
        break

if voz_encontrada:
    engine.setProperty('voice', voz_encontrada.id)
    print(f"‚úÖ Voz seleccionada: {voz_encontrada.name}")
else:
    print("‚ö†Ô∏è Voz preferida no encontrada. Usando voz por defecto.")
    print(f"Voces disponibles: {[voz.name for voz in engine.getProperty('voices')]}")

# Configuraci√≥n de la velocidad de habla y volumen
engine.setProperty("rate", 160)  # Velocidad de habla
engine.setProperty("volume", 0.9)  # Volumen


# Funci√≥n para limpiar el texto (eliminar caracteres innecesarios como # y *)
def clean_text(text):
    return text.replace("#", "").replace("*", "").replace("**", "").strip()


# Funci√≥n para convertir el texto en voz
def speak(text):
    text = clean_text(text)  # Limpiar el texto antes de hablar
    engine.say(text)
    engine.runAndWait()


# Funci√≥n para capturar la entrada de voz del usuario
def listen():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        try:
            recognizer.adjust_for_ambient_noise(source, duration=0.8)
            print("\nüé§ [Escuchando...]")
            audio = recognizer.listen(source, timeout=12, phrase_time_limit=18)
            text = recognizer.recognize_google(audio, language="es-ES")
            print(f"üë§ [Usuario]: {text}")
            return text
        except sr.WaitTimeoutError:
            print("‚è≥ [Sistema]: Tiempo de espera agotado")
            return None
        except Exception as e:
            print(f"‚ùå [Error]: {str(e)}")
            return None


# Funci√≥n para generar respuesta con el modelo local (LM Studio)
def generate_response_with_local_model(user_input, morfologia):
    try:
        # Convertir la morfolog√≠a a una descripci√≥n en texto
        descripcion_morfologia = (
            f"Tengo un rostro {morfologia['tipo_rostro']}, ojos {morfologia['ojos']} y piel {morfologia['color_piel']}."
        )

        # Datos de entrada para el modelo
        payload = {
            "model": NOMBRE_MODELO,
            "messages": [
                {
                    "role": "system",
                    "content": (
                        f"Eres un experto en maquillaje y belleza personal. "
                        f"Siempre me llamas '{NOMBRE_USUARIO}'. "
                        "Tu objetivo es asesorarme sobre maquillaje, cuidado de la piel, peinados y estilos de belleza. "
                        "Si la pregunta no es sobre estos temas, debes redirigir la conversaci√≥n a maquillaje o belleza. "
                        f"Mi informaci√≥n de belleza es la siguiente: {descripcion_morfologia}"
                    )
                },
                {"role": "user", "content": user_input}
            ],
            "temperature": 0.7,  # Nivel de creatividad del modelo
            "max_tokens": 300  # L√≠mite de tokens generados
        }

        # Realizar la petici√≥n POST al servidor
        response = requests.post(SERVER_URL, json=payload)

        # Si la respuesta es exitosa, procesarla
        if response.status_code == 200:
            response_data = response.json()
            answer = response_data.get('choices', [{}])[0].get('message', {}).get('content', '')

            # Si la respuesta no es sobre maquillaje, redirigir al tema correcto
            if "no relacionado" in answer.lower() or "pregunta fuera de tema" in answer.lower():
                return f"{NOMBRE_USUARIO}, recuerda que solo hablo sobre maquillaje y belleza. ¬øQuieres consejos de maquillaje?"

            return answer
        else:
            print(f"‚ö†Ô∏è Error al obtener la respuesta del modelo: {response.status_code}")
            return "Ocurri√≥ un error al procesar tu solicitud."

    except Exception as e:
        print(f"‚ö†Ô∏è Error al realizar la solicitud: {e}")
        return "Ocurri√≥ un error procesando tu solicitud."


# Funci√≥n para preguntar preferencias al usuario
def preguntar_preferencias():
    speak(f"{NOMBRE_USUARIO}, ¬øqu√© tipo de maquillaje prefieres hoy?")
    print(f"ü§ñ [GlamBot]: {NOMBRE_USUARIO}, ¬øqu√© tipo de maquillaje prefieres hoy?")
    preferencia = listen()

    if not preferencia:
        return "natural"  # Valor por defecto si no responde

    return preferencia


# Funci√≥n principal para interactuar con el asistente
def interact_with_assistant():
    print(f"ü§ñ [GlamBot]: Hola {NOMBRE_USUARIO}, soy GlamBot. ¬øEn qu√© puedo ayudarte hoy?")
    speak(f"Hola {NOMBRE_USUARIO}, soy GlamBot. ¬øEn qu√© puedo ayudarte hoy?")

    while True:
        user_input = listen()

        if not user_input:
            continue

        # Verificar si el usuario quiere salir
        if any(word in user_input.lower() for word in ["salir", "terminar", "adi√≥s"]):
            farewell = f"¬°Gracias por conversar, {NOMBRE_USUARIO}! Hasta la pr√≥xima."
            print(f"ü§ñ [GlamBot]: {farewell}")
            speak(farewell)
            break

        # Preguntar preferencias
        preferencia_maquillaje = preguntar_preferencias()

        # Generar respuesta con el modelo incluyendo las preferencias
        input_con_preferencia = f"{user_input}. Me gustar√≠a un maquillaje {preferencia_maquillaje}."
        response = generate_response_with_local_model(input_con_preferencia, MORFOLOGIA_USUARIO)

        print(f"ü§ñ [GlamBot]: {response}")
        speak(response)


# Ejecutar el asistente
if __name__ == "__main__":
    interact_with_assistant()
